# ğŸ§™â€â™‚ï¸ **Deep Research** ğŸ§ ğŸš€  
*AI-powered deep-dive research engine â€” rewritten in pure Python*

[![CI](https://github.com/meltmagic-agency/deep-research/actions/workflows/ci.yml/badge.svg)](https://github.com/meltmagic-agency/deep-research/actions/workflows/ci.yml)
![PyPI](https://img.shields.io/pypi/v/deep-research?color=orange&label=PyPI)
![Python Versions](https://img.shields.io/pypi/pyversions/deep-research)
![License](https://img.shields.io/github/license/meltmagic-agency/deep-research)

> **Build like Stark. ğŸš€ Research like a 100-person team.**  

---

## âœ¨ Why Youâ€™ll Love It
| ğŸ’¡ What It Does | ğŸ” How It Works |
|-----------------|----------------|
| **1. Explodes a single question** into multiple high-quality SERP queries. | LLM (OpenAI _o3-mini_ or DeepSeek R1) ğŸ“œ âœ JSON-validated queries |
| **2. Scours the web in parallel** | Firecrawl API âš¡ async + configurable concurrency |
| **3. Extracts smart learnings & next questions** | Token-aware prompt trimming ğŸª„ |
| **4. Loops recursively (breadth â†“, depth â†“)** | Unique learnings / URLs deduplicated |
| **5. Outputs eitherâ€¦** | â€¢ _a surgical one-liner answer_ âœ‚ï¸<br>â€¢ _a multi-page Markdown report_ ğŸ“‘ |

---

## ğŸš€ Quick Start

```bash
# 1 Â· Clone & enter
git clone https://github.com/meltmagic/deep-research.git
cd deep-research

# 2 Â· Add your keys
cp .env.example .env            # edit FIRECRAWL_KEY, OPENAI_KEY or FIREWORKS_KEY

# 3 Â· Install & run CLI
pip install -r requirements.txt
python -m deep_research         # interactive wizard ğŸ§™
```

### ğŸ³ Docker One-Liner
```bash
docker compose up              # API ğŸ‘‰ http://localhost:8000/docs
```

---

## âš™ï¸ Configuration (.env)
| Key | ğŸš¦ Required | ğŸ“ Description |
|-----|------------|---------------|
| `FIRECRAWL_KEY` | âœ… | Web search + scrape |
| `OPENAI_KEY` | âœ…* | LLM (o3-mini) |
| `FIREWORKS_KEY` | âœ…* | DeepSeek R1 alternative |
| `CUSTOM_MODEL` + `OPENAI_ENDPOINT` | âœ…* | Any OpenAI-compatible endpoint |
| `FIRECRAWL_CONCURRENCY` | â–«ï¸ | Parallel calls (default 2) |
| `CONTEXT_SIZE` | â–«ï¸ | Max tokens to send to LLM (default 128 000) |

\* Provide **one** of the three LLM options.

---

## ğŸ–¥ï¸ CLI Demo
```
$ python -m deep_research
â“ What would you like to research?  Impact of autonomous trucks on jobs
ğŸ“ Breadth (2-10) [4]:
ğŸ“ Depth (1-5) [2]:
ğŸ“„ Generate report or answer? (report/answer) [report]:
```
Outputs land in the **`reports/`** folder:  
`report.md` ğŸ““ or `answer.md` ğŸ’¬

---

## ğŸŒ REST API

| Verb | Endpoint | ğŸ¯ Purpose |
|------|----------|-----------|
| **POST** | `/api/research` | Concise `answer` + metadata |
| **POST** | `/api/generate-report` | Full `reportMarkdown` |
| **GET**  | `/api/healthz` | Liveness ping |

Example ğŸ‘‡
```http
POST /api/research
Content-Type: application/json

{
  "query": "Why did the 2024 GPU shortage happen?",
  "breadth": 3,
  "depth": 2
}
```

---

## ğŸ— Architecture Glimpse
```text
CLI / REST â†”ï¸ Orchestrator ğŸ”„
           â†™ï¸                  â†˜ï¸
    Firecrawl ğŸŒ          LLM ğŸ“
           â†˜ï¸                  â†™ï¸
          Markdown Report ğŸ“‘ / Exact Answer âš¡
```

---

## ğŸ›£ï¸ Roadmap
- ğŸ”Œ WebSocket progress stream  
- ğŸ›¡ï¸ RAG verification to curb hallucinations  
- ğŸ–¼ï¸ Streamlit front-end dashboard  
- ğŸ” Optional API-key auth middleware  

[ğŸ“¬ Open an issue](https://github.com/meltmagic-agency/deep-research/issues) to suggest features!

---

## ğŸ¤ Contributing
1. Fork â†’ `git checkout -b magic-feature`  
2. `poetry install` or `pip install -r requirements-dev.txt`  
3. Lint `ruff`, type-check `mypy`, test `pytest -q`  
4. PR with emoji-rich description ğŸ˜‰

---

## ğŸ“ License
**MIT** Â© 2025 MeltMagic Agency â€” Fork it, ship it, **make magic**. âœ¨
